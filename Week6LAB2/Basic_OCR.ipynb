{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNbiuzk72ogCdjlVducpzst"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introduction\n","\n","In this notebook, we will perform text detection in images using OCR. We will start with image preprocessing and then conduct OCR using Tesseract, EasyOCR, and KerasOCR. By the end of this notebook, you will understand how to enhance image quality for OCR and extract text effectively from images.\n","\n"],"metadata":{"id":"K09M7t6QvO9u"}},{"cell_type":"markdown","source":["# Install and Import Libraries"],"metadata":{"id":"4ZQ9DM7WvuE1"}},{"cell_type":"code","source":["!apt-get update\n","!apt-get install -y tesseract-ocr"],"metadata":{"id":"MOlqcxJjBPt5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pytesseract\n","!pip install easyocr\n","!pip install keras-ocr"],"metadata":{"id":"vUJvA1mCwkKi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w4j_TemAt-bM"},"outputs":[],"source":["import cv2\n","import pytesseract\n","import easyocr\n","import keras_ocr\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image"]},{"cell_type":"markdown","source":["# Image Preprocessing"],"metadata":{"id":"rFzJgIHtz3mq"}},{"cell_type":"code","source":["# Grayscale conversion\n","def get_grayscale(image):\n","    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","# Noise removal\n","def remove_noise(image):\n","    return cv2.medianBlur(image, 5)\n","\n","# Sharpening\n","def sharpen_image(image):\n","    kernel = np.array([[0, -1, 0], [-1, 5,-1], [0, -1, 0]])  # Sharpening kernel\n","    return cv2.filter2D(image, -1, kernel)\n","\n","# Binarization\n","def binarize_image(image):\n","    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n","\n","# Helper display function\n","def display_image(image, title, is_rgb=False):\n","    if is_rgb:\n","        # OpenCV loads images in BGR format by default, so we have to convert BGR to RGB for proper color display\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        plt.imshow(image)\n","    else:\n","        plt.imshow(image, cmap='gray')\n","    plt.title(title)\n","    plt.axis('off')\n","    plt.show()"],"metadata":{"id":"ax5yamvmxt-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_path = 'Basic_OCR.png'\n","image = cv2.imread(image_path)\n","\n","display_image(image, \"Original Image\",  is_rgb=True)\n","\n","gray_image = get_grayscale(image)\n","display_image(gray_image, \"Grayscale Image\")\n","\n","\n","denoised_image = remove_noise(gray_image)\n","display_image(denoised_image, \"Denoised Image\")\n","\n","\n","sharpened_image = sharpen_image(denoised_image)\n","display_image(sharpened_image, \"Sharpened Image\")\n","\n","\n","binarized_image = binarize_image(sharpened_image)\n","display_image(binarized_image, \"Binarized Image\")"],"metadata":{"id":"Jrztq9VE1c_3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Text Detection using Tesseract"],"metadata":{"id":"MdkBLgOGAyGi"}},{"cell_type":"markdown","source":["Drawing Bounding Boxes"],"metadata":{"id":"jA1JvQHgWSFw"}},{"cell_type":"code","source":["image_path = 'Basic_OCR.png'\n","image = cv2.imread(image_path)\n","\n","boxes = pytesseract.image_to_boxes(gray_image)\n","boxes_image = image.copy()\n","\n","for box in boxes.splitlines():\n","    box = box.split(' ')\n","    x, y, w, h = int(box[1]), int(box[2]), int(box[3]), int(box[4])\n","    # Draw the rectangle\n","    cv2.rectangle(boxes_image, (x, boxes_image.shape[0] - y), (w, boxes_image.shape[0] - h), (0, 255, 0), 2)\n","\n","display_image(boxes_image, \"Image with Bounding Boxes\", is_rgb=True)"],"metadata":{"id":"-mQ0KO98WVAW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Extract text"],"metadata":{"id":"RRcSCb_tXy1l"}},{"cell_type":"code","source":["# Apply any type of preprocessing if needed\n","gray_image = get_grayscale(image)\n","\n","extracted_text = pytesseract.image_to_string(gray_image)\n","print(extracted_text)"],"metadata":{"id":"57tCJ6t91mgp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Text Detection using EasyOCR"],"metadata":{"id":"8sZGVxgDENs6"}},{"cell_type":"code","source":["# Initializing  EasyOCR reader\n","reader = easyocr.Reader(['en'])  #  'en' for English language"],"metadata":{"id":"zxqU2gNrGRmy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_path = 'Basic_OCR.png'\n","image = cv2.imread(image_path)\n","\n","result = reader.readtext(image)\n","\n","print (result)"],"metadata":{"id":"tG1Qsgs2Bc87"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Print only the detected words"],"metadata":{"id":"DMl9_q1UZoKu"}},{"cell_type":"code","source":["for detection in result:\n","    print(detection[1])"],"metadata":{"id":"BS_FoVaqZpPP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Draw bounding box"],"metadata":{"id":"4V_w7k4gZ_bt"}},{"cell_type":"code","source":["for detection in result:\n","    bounding_box = detection[0]\n","\n","    top_left = tuple([int(coord) for coord in bounding_box[0]])\n","    bottom_right = tuple([int(coord) for coord in bounding_box[2]])\n","\n","\n","    cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n","\n","display_image(image, \"Image with Bounding Boxes\", is_rgb=True)"],"metadata":{"id":"MsT23x1haC2W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Text Detection using KerasOCR"],"metadata":{"id":"G3014NjxLoKB"}},{"cell_type":"code","source":["# Warning! Don't run this code unless you had an error when creating a pipeline for OCR using KerasOCR in the next code cell\n","#!pip install tensorflow==2.9.1 keras==2.9.0\n","# After runnig this code you will have to restart the session and import libraries again"],"metadata":{"id":"nqz-Ji4BMa0T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a pipeline for OCR using KerasOCR\n","pipeline = keras_ocr.pipeline.Pipeline()"],"metadata":{"id":"zB2VHkWDGLSd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_path = 'Basic_OCR.png'\n","\n","image = keras_ocr.tools.read(image_path)\n","\n","# KerasOCR requires the image to be passed as a list, even if you're working with a single image\n","images = [image]\n","\n","# Perform OCR on the image\n","prediction_groups = pipeline.recognize(images)\n","\n","# Print the recognized text\n","for predictions in prediction_groups:\n","    for prediction in predictions:\n","        print(prediction[0])"],"metadata":{"id":"kWBt79yVLr2W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["KerasOCR provides a built-in method `keras_ocr.tools.drawAnnotations()` that simplifies the process of drawing bounding boxes and displaying text annotations on images."],"metadata":{"id":"rDtF59q3bCQ0"}},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(10, 10))\n","keras_ocr.tools.drawAnnotations(image=images[0], predictions=prediction_groups[0], ax=ax)\n","\n","\n","plt.title(\"Image with KerasOCR Annotations\")\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"x-7pj3Y6PO3F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9d7mZkmFbJk5"},"execution_count":null,"outputs":[]}]}